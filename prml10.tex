%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 第10章
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\setcounter{chapter}{9}
\chapter{「近似推論法」の数式の補足}
この文章は『パターン認識と機械学習』（PRML）の10章の式変形を一部埋めたものです.

\section{この章でよく使われる公式}
9章と同じようによく使う公式を列挙しておく.
\subsection{ガンマ関数}
$$
\Gamma(x)=\int_0^\infty t^{x-1} e^{-t}\,dt, \quad \Gamma(x+1)=x\Gamma(x).
$$
ディガンマ関数
$$
\phi(x)=\dif{x} \log \Gamma(x).
$$

\subsection{ディリクレ分布}
$0 \le \mu_k \le 1$, $\sum_k \mu_k = 1$, $\hat{\alpha}=\sum_k \alpha_k$として
$$
\Dir(\mu|\alpha)=C(\alpha)\prod_{k=1}^K \mu_k ^{\alpha_k-1}, \quad C(\alpha)=\frac{\Gamma(\hat{\alpha})}{\prod_k \Gamma(\alpha_k)}, \quad
E[\mu_k]=\frac{\alpha_k}{\hat{\alpha}}.
$$
\subsection{ガンマ分布}
$$
\Gam(\tau|a,b)=\frac{1}{\Gamma(a)}b^a\tau^{a-1}e^{-b\tau}, \quad
E[\tau]=\frac{a}{b}, \quad \var[\tau]=\frac{a}{b^2}, \quad E[\log \tau]=\phi(a)-\log b.
$$
\subsection{正規分布}
$$
\calN = \calN(x|\mu,\Sigma)=\frac{1}{(2\pi)^{D/2}}|\Sigma|^{-1/2}\exp\left(-\half\quads{{\Sigma^{-1}}}{(x-\mu)}\right).
$$
$$
E[x]=\mu, \quad \cov[x]=\Sigma, \quad E\left[\outp{x}\right]=\outp{\mu}+\Sigma, \quad E\left[\inp{x}\right]=\inp{\mu}+\tr(\Sigma).
$$
$p(x)=\calN(x|\mu,\Lambda^{-1})$, $p(y|x)=\calN(x|Ax+b, L^{-1})$のとき
$$
p(y)=\calN(y|A\mu + b, L^{-1} + A\Lambda^{-1}\trans{A}).
$$
\subsection{スチューデントのt分布}
\begin{eqnarray*}
&&
\St(x|\mu,\Lambda,\nu)
=\frac{\Gamma\left(\frac{\nu+D}{2}\right)}{\Gamma\left(\frac{\nu}{2}\right)}
\frac{|\Lambda|^{1/2}}{(\pi \nu)^{1/2}}\left(1+\frac{\triangle^2}{\nu}\right)^{-\frac{\nu+1}{2}},
\\&& \triangle^2=\quads{\Lambda}{(x-\mu)},
\quad E[x]=\mu.
\end{eqnarray*}
\subsection{ウィシャート分布}
$$
\calW(\Lambda,W,\nu)=B(W,\nu)|\Lambda|^{\frac{\nu-D-1}{2}}\exp\left(-\half\tr (W^{-1}\Lambda)\right).
$$
$$
B(W, \nu)=|W|^{\nu/2}\left(2^{\nu D/2} \pi ^{D(D-1)/4} \prod_{i=1}^D \Gamma\left(\frac{\nu+1-i}{2}\right)\right)^{-1}.
$$
\begin{eqnarray*}
&& E[\Lambda]=\nu W.\\
&& E[\log|\Lambda|]=\sum_{i=1}^D \phi\left(\frac{\nu+1-i}{2}\right)+D \log 2 + \log |W|.\\
&& H[\Lambda]=-\log B(W,\nu)-\frac{\nu-D-1}{2}E[\log |\Lambda|]+\frac{\nu D}{2}.
\end{eqnarray*}

\subsection{行列の公式}
\begin{eqnarray*}
&& \quads{A}{x}=\tr(Ax\trans{x}).\\
&& \dif{A}\log|A|=\trans{(A^{-1})}.\\
&& \dif{x}\log|A|=\tr\left(A^{-1}\dif{x}A\right).\\
&& \dif{A}\tr(A^{-1}B) = -\trans{(A^{-1}BA^{-1})}.\\
&& |I+a\trans{b}|=1+\trans{a}b.
\end{eqnarray*}

\subsection{カルバック距離}
$$
\KL(q||p)=-\int q(Z) \log \frac{p(Z|X)}{q(Z)}\,dZ \ge 0.
$$

\section{下限と下界}\label{lower_bound}
下界（lower bound）と下限（inf, greatest lower bound）は意味が違う.
できるだけ使い分けた方がよいだろう. 一般には順序集合に対して定義するがここでは実数の話に制限する.
$A$が$\RR$の部分集合とする. ある$x$に対して$x$が$A$の下界であるとは, 全ての$a\in A$に対して$x \le a$であることをいう.
つまり$x$は$A$の中の一番小さい値よりも同じかより小さいときのことをいう.

たとえば$A=\{x|x\ge 0\}$のとき, $-3$は$A$の下界である. $-5$も$A$の下界である.
普通下界となる値はたくさんあるので主語と述語を入れ換えた「$A$の下界は$-3$である」という言い方はあまりしないと思う.
これは「$x^2=1$の解は1である」とは言わないのと同じ感覚である（$-1$はどうしたの?と聞かれるだろう）.

たくさんある下界の中で一番大きい値を下限という. 下限は存在すればただ一つである.
上記$A$の下限は0. 一つしかないので「$A$の下限は0である」ともいうし, 「0は$A$の下限である」ともいう.

たとえばPRML上巻（4刷）p.49の一番下では
「確率変数の状態を送るために必要なビット数の下限がエントロピーである」
とありこれは正しい. あるいは
「エントロピーは確率変数の状態を送るために必要なビット数の下限である」
でもよい. しかし, これを
「エントロピーは確率変数の状態を送るために必要なビット数の下界である」
としてしまうと（2011/7/27時点での日本語サポートの正誤表）,
間違ってはいないが上の文章と全然意味が違ってしまう.
これではエントロピーがぎりぎりの値であるという主張が消えたしょうもないものになっている.

\section{分解による近似の持つ性質}
ここで$\Lambda_{ij}$はスカラーで$\Lambda_{12}=\Lambda_{21}$.
$E[z_1] = m_1$, $E[z_2] = m_2$より
\begin{eqnarray*}
m_1 &=& \mu_1 - \Lambda_{11}^{-1}\Lambda_{12}(m_2 - \mu_2)
    = \mu_1 - \Lambda_{11}^{-1}\Lambda_{12}(\mu_2 - \Lambda_{22}^{-1}\Lambda_{21}(m_1-\mu_1) - \mu_2) \\
    &=& \mu_1 + \Lambda_{11}^{-1}\Lambda_{22}^{-1}\Lambda_{12}^2(m_1-\mu_1).
\end{eqnarray*}
よって
$$
(m_1-\mu_1)(\Lambda_{11}^{-1}\Lambda_{22}^{-1}\Lambda_{12}^2-1)=0.
$$
分布が非特異なら$|\Lambda|=\Lambda_{11}\Lambda_{22}-\Lambda_{12}^2 \ne0$より$m_1=\mu_1$. 同様に $m_2=\mu_2$.

変数$Z=\{z_1, \ldots, z_N \}$に対する分布$q(Z)$が
$$
q(Z)=\prod_{i=1}^M q_i(Z_i)
$$
と複数のグループの関数の積としてかけていると仮定する. ここで$\{Z_i\}$は$Z$のdisjoint-unionである.
（PRML p.182）$\KL(p||q)$を$Z_j$について最小化する問題を考える（以下, 対象変数以外の項をまとめて$C$と略記する）.
\begin{eqnarray*}
\KL(p||q) &=& -\int p(Z) \left(\sum_i \log q_i(Z_i)\right)\,dZ + C \\
   &=& -\int \left(p(Z) \log q_j(Z_j) + p(Z) \sum_{i \ne j} \log q_i(Z_i)\right)\,dZ + C \\
   &=& -\int p(Z) \log q_j(Z_j)\,dZ + C
   = -\int \log q_j(Z_j)\underbrace{\left(\int p(Z) \prod_{i\ne j}\,dZ_i\right)}_{=:F_j(Z_j)}\,dZ_j\\
   &=& -\int F_j(Z_j) \log q_j(Z_j)\,dZ_j.
\end{eqnarray*}
$$
\int q_j(Z_j)\,dZ_j=1
$$
の条件の元で
$$
X=-\int F_j(Z_j) \log q_j(Z_j)\,dZ_j + \lambda \left(\int q_j(Z_j)\,dZ_j-1\right)
$$
を最小化する.
\begin{eqnarray*}
\dif{q_j}X &=& -\int F_j(Z_j) \log (q_j + \delta q_j)\,dZ_j + \lambda \left(\int (q_j + \delta q_j)\,dZ_j-1\right)\\
 &=&\left(-\int F_j(Z_j) \log q_j\,dZ_j + \lambda \left(\int q_j\,dZ_j - 1\right)\right)-\left(\int F_j(Z_j)/q_j\,dZ_j - \lambda\right)\delta q_j
\\
 &=& 0.
\end{eqnarray*}
$F_j/q_j - \lambda = 0.$
よって$F_j=\lambda q_j$. 積分して
$$
\int F_j\,dZ_j = \int \lambda q_j\,dZ_j=\lambda=1.
$$
よって
$$
q_j^*(Z_j)=q_j=F_j=\int p(Z) \prod_{i \ne j}\,dZ_i.
$$
\section{$\alpha$ダイバージェンス}
$\alpha$を実数として
$$
D_\alpha(p||q)=\frac{4}{1-\alpha^2}\left(1-\int p(x)^{(1+\alpha)/2} q(x)^{(1-\alpha)/2}\,dx\right)
$$
を$\alpha$ダイバージェンスという.
$\alpha \rightarrow 1$のとき$\KL(p||q)$, $\alpha \rightarrow -1$のとき$\KL(q||p)$になる.

（証明）$\alpha=1-2\epsilon$と置く. $\alpha \rightarrow 1$で$\epsilon \rightarrow 0$となる.
$$
(q/p)^\epsilon=\exp\left(\epsilon \log(q/p)\right) \approx 1 + \epsilon \log(q/p)
$$
より
\begin{eqnarray*}
D_\alpha(p||q)
 &=& \frac{1}{\epsilon(1-\epsilon)}\left(1-\int p(q/p)^\epsilon\,dx\right)
 \simeq \frac{1}{\epsilon}\left(1-\int p\left(1+\epsilon \log \frac{q}{p}\right)\,dx\right) \\
 &=& \frac{1}{\epsilon}\left(-\epsilon \int p \log \frac{q}{p}\,dx\right)=\KL(p||q).
\end{eqnarray*}
$\alpha \rightarrow -1$も同様.

\section{例：一変数ガウス分布}
ガウス分布から独立に発生した観測値$x$のデータセットを$\calD=\{x_1,\ldots,x_N\}$とする.
もとのガウス分布の平均$\mu$と精度$\tau$の事後分布をもとめる.
$$
p(D|\mu,\tau)=\left(\frac{\tau}{2\pi}\right)^{N/2} \exp\left(-\frac{\tau}{2}\sum_n (x_n-\mu)^2\right).
$$
$$
p(\mu|\tau)=\calN(\mu|\mu_0, (\lambda_0\tau)^{-1}), \quad p(\tau)=\Gam(\tau|a_0, b_0).
$$
この問題は厳密にもとめられるがここでは事後分布が次のように分解できると仮定したときの変分近似を考える.
$$
q(\mu,\tau)=q_\mu(\mu)q_\tau(\tau).
$$
まず$\mu$について
\begin{eqnarray*}
\log q_\mu^*(\mu)
 &=& E_\tau[\log p(D,\mu,\tau)]\\
 &=& E_\tau[\log p(D|\mu,\tau)+\log p(\mu|\tau)] + \text{（$\mu$に依存しない部分$C$）}\\
 &=& \frac{E[\tau]}{2}\left(\sum_n (x_n-\mu)^2\right)+E_\tau\left[-\frac{\lambda_0 \tau}{2}(\mu-\mu_0)^2\right] + C\\
 &=&-\left(E[\tau]/2\right)\left(\lambda_0(\mu-\mu_0)^2+\sum_n (x_n-\mu)^2\right) + C.
\end{eqnarray*}
$\mu$について平方完成すると
\begin{eqnarray*}
&& -(E[\tau]/2)\left((\lambda_0+N)\mu^2-2\mu\left(\lambda_0\mu_0+\sum_n x_n\right)+\lambda_0 \mu_0^2+\sum_n x_n^2\right) + C\\
&& \sum_n x_n=N \bar{x}より\\
&=& -\frac{E[\tau](\lambda_0 + N)}{2}\left(\mu-\frac{\lambda_0 \mu_0 + N\bar{x}}{\lambda_0 + N}\right)^2+\cdots.
\end{eqnarray*}
よってこの分布はガウス分布であることが分かり,
$$
\mu_N=\frac{\lambda_0 \mu_0 + N\bar{x}}{\lambda_0 + N}, \quad, \lambda_N=(\lambda_0+N)E[\tau]
$$
と置くと$\calN(\mu|\mu_N,\lambda_N^{-1})$となることが分かる.
$N\rightarrow \infty$のとき$\mu_N \rightarrow \bar{x}$で分散は0（精度は$\infty$）.
$\tau$について
\begin{eqnarray*}
\log q_\tau^*(\tau)
 &=& E_\mu\left[\log p(D,\tau|\mu)\right]=E_\mu\left[\log p(D|\mu,\tau)+\log p(\mu|\tau)\right]+\log p(\tau)\\
 &=& E_\mu\left[(N/2)\log \tau - (\tau/2) \sum_n (x_n-\mu)^2\right]\\
 & & + E_\mu\left[(1/2)\log (\lambda_0 \tau) - (\lambda_0 \pi/2)(\mu-\mu_0)^2\right]\\
 & & + E_\mu\left[(a_0-1)\log \tau - b_0 \tau - \log \Gamma(a_0)+a_0 \log b_0\right] + C\\
 &=& (a_0-1)\log \tau - b_0 \tau + (N+1)/2 \log \tau\\
 &-& (\tau/2)E_\mu\left[\sum_n (x_n-\mu)^2+\lambda_0(\mu-\mu_0)^2\right] + C.
\end{eqnarray*}
よって$q_\tau(\tau)$はガンマ分布となり
$$
a_N=a_0+\frac{N+1}{2}, \quad b_N=b_0+\half E_\mu\left[\sum_n (x_n-\mu)^2+\lambda_0 (\mu-\mu_0)^2\right]
$$
と置くと$q_\tau(\tau)=\Gam(\tau|a_N, b_N)$.
$q_\mu(\mu)$, $q_\tau(\tau)$の関数の形に何も仮定を置いていないのに, 尤度関数と共役事前分布の構造から決まったことに注意.
$N \rightarrow \infty$で
$$
E[\Gam(\tau|a_N, b_N)]=\frac{a_N}{b_N} \rightarrow 1/E_\mu\left[(1/N\sum_n (x_n-\mu)^2\right] \rightarrow 1/{\text 分散}.
$$
$$
\sigma[\Gam] = a_N / b_N^2 \rightarrow 0.
$$
$\mu_0=a_0=b_0=\lambda_0=0$という無情報事前分布を入れてみる.
$$
a_N=\frac{N+1}{2}, \quad b_N=\half E_\mu\left[\sum_n (x_n-\mu)^2\right].
$$
よって
$$
E[\tau]^{-1}=\frac{b_N}{a_N}=E\left[\frac{1}{N+1}\sum_n (x_n-\mu)^2\right]=\frac{N}{N+1}\left(\overline{x^2}-2\bar{x}E[\mu]+E[\mu^2]\right).
$$
$$
\mu_N=\frac{0+N\bar{x}}{0+N}=\bar{x}, \quad \lambda_N=N E[\tau].
$$
よって
$$
E[\mu]=\bar{x}, \quad E[\mu^2]=E[\mu]^2 + \frac{1}{\lambda_N}=\bar{x}^2+\frac{1}{N E[\tau]}.
$$
$$
\frac{1}{E[\tau]}=\frac{N}{N+1}\left(\bar{x}^2-2\bar{x}^2+\bar{x}^2+\frac{1}{N E[\tau]}\right).
$$
$$
\frac{N}{N+1}(\overline{x^2}-\bar{x}^2)=\frac{1}{E[\tau]}-\frac{1}{N+1}\frac{1}{E[\tau]}=\frac{N}{N+1}\frac{1}{E[\tau]}.
$$
よって
$$
\frac{1}{E[\tau]}=\overline{x^2}-\bar{x}^2=\frac{1}{N}\sum_n (x_n-\bar{x})^2.
$$

\section{モデル比較}
事前確率$p(m)$を持つ複数のモデルの比較. 観測データ$X$の下で事後確率$p(m|X)$を近似したい.
$$
q(Z, m)=q(Z|m)q(m), \quad p(X, Z, m)=p(X)p(Z, m|X).
$$
$\sum_{m,Z} q(Z, m)=1$に注意して
\begin{eqnarray*}
\log p(X)
 &=& \sum_{m,Z} q(Z,m) \log p(X)
 = \sum_{m,Z} q(Z,m) \log \frac{p(X,Z,m)}{q(Z,m)}\frac{q(Z,m)}{p(Z,m|X)}\\
 &=& \underbrace{\left(\sum_{m,Z} q(Z,m) \log \frac{p(X,Z,m)}{q(Z,m)}\right)}_{:=\calL}
      +\left( \sum_{m,Z} q(Z,m) \log\frac{q(Z,m)}{p(Z,m|X)}\right)\\
 &=& \calL - \sum_{m,Z} q(Z,m) \log \frac{q(Z,m|X)}{q(Z,m)}
 = \calL - \sum_{m,Z} q(Z|m) q(m) \log \frac{p(Z,m|X)}{q(Z|m)q(m)}.
\end{eqnarray*}
$\calL$を$q(m)$について最大化する.
$\sum_Z q(Z|m)=1$に注意して
\begin{eqnarray*}
\calL
 &=& \sum_{m,Z} q(Z|m)q(m)\left(\log p(Z,X|m)+\log p(m)-\log q(Z|m)-\log q(m)\right)\\
 &=& \sum_m q(m)\left((\log p(m)-\log q(m))
     + \underbrace{\sum_Z q(Z|m) \log \frac{p(Z,X|m)}{q(Z|m)}}_{=:\calL_m}\right),\\
 &=&\sum_m q(m) \log \frac{p(m) \exp \calL_m}{q(m)}
  = -\sum_m \KL(q(m)||p(m) \exp \calL_m).
\end{eqnarray*}
よって$\calL$が最大となるのはカルバック距離が最小となるとき, つまり$q(m) \propto p(m) \exp \calL_m$のときである（$p(m)\exp \calL_m$は正規化されているとは限らないので$=$ではなく$\propto$）.

\subsection{変分混合ガウス分布}
ガウス混合モデルに変分推論法を適用してみる.
$x_n$に対応する潜在変数$z_n$. $z_n$は$K$個の要素$z_{nk}$からなる.
$z_{nk}=0$または1で$\sum_k z_{nk}=1$.
\begin{eqnarray*}
&&
X=\{x_1, \ldots, x_N\},
\quad Z=\{z_1, \ldots, z_N\},
\quad \text{混合比は}\vpi=(\pi_1, \ldots, \pi_K),
\\&&
p(z_n)=\prod_k \pi_k^{z_{nk}}, \quad p(x_n|z_n)=\prod_k \calN(x_n|\mu_k, \Sigma_k)^{z_{nk}},
\\&&
p(X|Z,\mu,\Lambda)=\prod_{n,k} \calN(x_n|\mu_k, \Lambda_k^{-1})^{z_{nk}}.
\end{eqnarray*}
$\vpi$の事前分布はディリクレ分布とする.
$$
p(\vpi)=\Dir(\vpi|\alpha_0)=C(\alpha_0)\prod_k \pi_k^{\alpha_0-1}.
$$
混合要素の持つガウス分布の事前分布はガウス・ウィシャート分布とする.
$$
p(\mu,\Lambda)=p(\mu|\Lambda)p(\Lambda)=\prod_k \calN(\mu_k|m_0, (\beta_0 \Lambda_k)^{-1})\calW(\Lambda_k,|W_0,\nu_0).
$$

\subsection{変分事後分布}
$$
p(X,Z,\vpi,\mu,\Lambda)=p(X|Z,\mu,\Lambda)p(z|\vpi)p(\vpi)p(\mu|\Lambda)p(\Lambda).
$$
$q(Z,\vpi,\mu,\Lambda)=q(Z)q(\vpi,\mu,\Lambda)$という変分近似を考える.

$Z$について（以後対象としている変数以外の項は無視する）
\begin{eqnarray*}
&&\log q^*(Z)\\
 &&= E_{\vpi,\mu,\Lambda}[\log p(X,Z,\vpi,\mu,\Lambda)]
 = E_{\vpi}[\log p(Z|\vpi)]+E_{\mu,\Lambda}[\log p(X|Z,\mu,\Lambda)]\\
 &&= \sum_{n,k} z_{nk} E_{\vpi}[\log \pi_k]
 \\&&\hphantom{={}}\quad
 + \sum_{n,k} z_{nk} E_{\mu,\Lambda}\left[\half\log |\Lambda_k|-\half\quads{\Lambda_k}{(x_n-\mu_n)}-\frac{D}{2}\log (2\pi)\right]\\
 &&= \sum_{n,k} z_{nk}
   \left(
     E_\pi[\log \pi_k]
     +\half E[\log |\Lambda_k|]
     -\frac{D}{2}\log (2\pi)
   \right.\\
 &&\hphantom{= \sum_{n,k} z_{nk}}
 \underbrace{\qquad\qquad
   \left.
   -\half E_{\mu_k,\Lambda_k}[\quads{\Lambda_k}{(x_n-\mu_k)}]
   \right)}_{=:\log \rho_{nk}}
 \\
 &&= \sum_{n,k} z_{nk} \log \rho_{nk}.
\end{eqnarray*}
よって
$$
q^*(Z) \propto \prod_{n,k} \rho_{nk}^{z_{nk}}.
$$
$Z$について総和をとると$\sum_k z_{nk}=1$より
$$
\sum_Z \prod_{n,k} \rho_{nk}^{z_{nk}}=\prod_n \left(\sum_k \rho_{nk}\right).
$$
よって
$$
r_{nk}=\rho_{nk}/\left(\sum_k \rho_{nk}\right)
$$
と置くと
$$
q^*(Z)=\prod_{n,k} r_{nk}^{z_{nk}}
$$
とできる. $q(Z)$の最適解は事前分布$p(Z|\vpi)$と同じ形. $\rho_{nk}=e^?$の形なので$\rho_{nk} \ge 0$.
つまり$r_{nk} \ge 0$. 各$n$について$\sum_k r_{nk}=1$
$$
E[z_{nk}]=r_{nk}.
$$
次の値を定義する：
$$
N_k=\sum_n r_{nk}, \quad \bar{x}_k = \frac{1}{N_k}\sum_n r_{nk} x_n, \quad S_k = \frac{1}{N_k} \sum_n r_{nk}\outp{(x_n-\bar{x}_k)}.
$$
$q(\vpi,\mu,\Lambda)$について考える.
\begin{eqnarray*}
\log q^*(\vpi,\mu,\Lambda)
 &=& E_Z\left[\log p(X,Z,\vpi,\mu,\Lambda)\right]\\
 &=& \log p(\vpi) + \sum_k \log p(\mu_k, \Lambda_k)\\
 &+& E_Z[\log p(Z|\vpi)] + \sum_{n,k} E[z_{nk}] \log \calN(x_n|\mu_k,\Lambda_k^{-1}).
\end{eqnarray*}
この式は$\vpi$だけを含む項とそれ以外の項に分かれている. 更に$\mu_k$, $\Lambda_k$の積にもなっている.
つまり$q(\vpi,\mu,\Lambda)=q(\vpi) \prod_k q(\mu_k, \Lambda_k)$という形になっている.
$\vpi$に依存する部分を見る.
\begin{eqnarray*}
\log q^*(\vpi)
 &=& \log \Dir (\vpi|\alpha_0) + E_Z\left[\sum_{n,k} z_{nk} \log \pi_k\right]\\
 &=& (\alpha_0-1)\sum_k \log \pi_k + \sum_{n,k} r_{nk} \log \pi_k
 = \sum_k \left(\alpha_0-1+\sum_n r_{nk}\right)\log \pi_k.
\end{eqnarray*}
よって$q^*(\vpi)$はディリクレ分布となる.
その係数は$\alpha_k=\alpha_0 + N_k$とおいて$\alpha=(\alpha_k)$とすると$q^*(\vpi)=\Dir(\vpi|\alpha)$.
$q^*(\mu_k,\Lambda_k)=q^*(\mu_k|\Lambda_k) q^*(\Lambda_k)$を考える.
まず
\begin{eqnarray*}
\log q^*(\mu_k,\Lambda_k)
 &=& \log \calN(\mu_k|m_0, (\beta_0 \Lambda_k)^{-1})
    +\log \calW(\Lambda_k|W_0,\nu_0)
 \\&&
    +\sum_n r_{nk} \log \calN(x_n|\mu_k,\Lambda_k^{-1})\\
 && （\mu_k, \Lambda_k{\text の依存部分だけとりだして}）\\
 &=&\half\log |\beta_0 \Lambda_k|-\half\quads{\beta_0 \Lambda_k}{(\mu_k-m_0)}
      +\frac{\nu_0-D-1}{2}\log |\Lambda_k|\\
 && - \half\tr (W_0^{-1}\Lambda_k) + \sum_n r_{nk} \left(\half\log |\Lambda_k|-\half\quads{\Lambda_k}{(x_n-\mu_k)}\right).
\end{eqnarray*}
このうち更に$\mu_k$に依存する部分をみる：
\begin{eqnarray*}
\log q^*(\mu_k|\Lambda_k)
 &=& -\half\quads{\left(\beta_0 + \sum_n r_{nk}\right)\Lambda_k}{\mu_k}
      + \trans{\mu_k}\Lambda_k\left(\beta_0 m_0 + \sum_n r_{nk} x_n\right)\\
 && （\beta_k := \beta_0 + N_k, \quad m_k := \frac{1}{\beta_k}(\beta_0 m_0 + N_k \bar{x}_k) {\text と置くと}）\\
 &=&-\half\quads{{(\beta_k \Lambda_k)}}{\mu_k} + \trans{\mu_k}(\beta_k \Lambda_k) m_k.
\end{eqnarray*}
よって
$$
q^*(\mu_k|\Lambda_k)=\calN(\mu_k|m_k, (\beta_k \Lambda_k)^{-1}).
$$
残りを考える.
\begin{eqnarray*}
\log q^*(\Lambda_k)
 &=& \log q^*(\mu_k,\Lambda_k) - \log q^*(\mu_k|\Lambda_k)\\
 &=& \half\log |\beta_0 \Lambda_k| - \half\quads{(\beta_0 \Lambda_k)}{(\mu_k-m_0)}+\frac{\nu_0-D-1}{2}\log |\Lambda_k| \\
     && - \half\tr(W_0^{-1}\Lambda_k) + \half N_k \log |\Lambda_k|
        -\half\sum_n r_{nk} \quads{\Lambda_k}{(x_n-\mu_k)}\\
     && - \half\log |\beta_0 \Lambda_k| + \half\quads{(\beta_0 \Lambda_k)}{(\mu_k-m_k)}\\
 &=& \frac{(\nu_0+N_k)-D-1}{2}\log |\Lambda_k|
      -\half\tr\Bigl((\beta_0 \Lambda_k)\outp{(\mu_k-m_0)}\\
  &&  + \sum_n r_{nk} \Lambda_k \outp{(x_n-\mu_k)}-\beta_k \Lambda_k \outp{(\mu_k-m_k)}\Bigr)\\
  &&  - \half(\Lambda_k W_0^{-1})\\
  && \text{（$\nu_k:=\nu_0 + N_k$と置く）}\\
 &=& \frac{\nu_k-D-1}{2}\log |\Lambda_k| - \half\tr\Bigl(\Lambda_k\bigl(W_0^{-1}+\beta_0\outp{(\mu_k-m_0)}\\
 && +\sum_n r_{nk}\outp{(x_n-\mu_k)}-\beta_k\outp{(\mu_k-m_k)}\bigr)\Bigr)\\
 &=& \frac{\nu_k-D-1}{2}\log |\Lambda_k| - \half\tr(\Lambda_k W_k^{-1}) \text{と置く}.
\end{eqnarray*}

$W_k$を求めよう. まず
\begin{eqnarray}\label{r_nk_outp_x_n}
\sum_n r_{nk}\outp{x_n}
 &=& \sum_n r_{nk}\left(\outp{(x_n-\bar{x}_k)}+2x_n \bar{x}_k-\outp{{\bar{x}}}\right)\nonumber\\
 &=& N_k S_k + 2_Nk + 2N_k \outp{\bar{x}_k} - N_k \outp{\bar{x}_k}\nonumber\\
 &=& N_k S_k + N_k \outp{\bar{x}_k}.
\end{eqnarray}
よって
\begin{eqnarray*}
&&W_k^{-1}\\
 &&= W_0^{-1}+\beta_0\left(\outp{\mu_k}-2\mu_k \trans{m_0}+\outp{m_0}\right)
      +N_k S_k + N_k \outp{\bar{x}_k}-2\sum_n r_{nk} x_n \trans{\mu_k}\\
 &&\hphantom{={}}
    + \sum_n r_{nk} \outp{\mu_k} -(\beta_0 + N_k)\Bigl(\outp{\mu_k}-2\mu_k \frac{1}{\beta_k}\trans{(\beta_0 m_0+N_k\bar{x}_k)}\\
 &&\hphantom{={}}
    + \frac{1}{\beta_k^2}\outp{(\beta_0 m_0 + N_k \bar{x}_k)}\Bigr)\\
 &&\hphantom{={}} \text{（$\sum_n r_{nk} = N_k$に注意して）}\\
 &&= W_0^{-1} + N_k S_k + \beta_0 \outp{m_0}+N_k \outp{\bar{x}_k}\\
 &&\hphantom{={}}
   - \frac{1}{\beta_k}\left(\beta_0^2 \outp{m_0}+2 \beta_0 N_k m_0 \trans{\bar{x}_k}+N_k^2 \outp{\bar{x}_k}\right)\\
 &&= W_0^{-1} + N_k S_k + \frac{(\beta_0 + N_k)\beta_0 - \beta_0^2}{\beta_k}\outp{m_0}
    + \frac{(\beta_0 + N_k)N_k-N_k^2}{\beta_k}\outp{\bar{x}_k}
 \\&&\hphantom{={}}
    - \frac{2\beta_0 N_k}{\beta_k}m_0 \trans{\bar{x}_k}\\
 &&= W_0^{-1} + N_k S_k + \frac{\beta_0 N_k}{\beta_k}\outp{(m_0-\bar{x}_k)}.
\end{eqnarray*}
よって
$$
q^*(\Lambda_k)=\calW(\Lambda_k|W_k,\nu_k), \quad
  q^*(\mu_k,\Lambda_k)=\calN(\mu_k|m_k,(\beta_k \Lambda_k)^{-1}) \calW (\Lambda_k|W_k,\nu_k).
$$

$\calN(x|\mu,\Lambda^{-1})$について$E[\outp{x}]=\outp{\mu}+\Lambda^{-1}$, $\calW(\Lambda_k|W_k,\nu_k)$について$E[\Lambda_k]=\nu_k W_k$なので
\begin{eqnarray}\label{eval_quad}
&& E_{\mu_k,\Lambda_k}[\quads{\Lambda_k}{(x_n-\mu_k)}]\nonumber \\
 &=& \tr\left(E\left[\Lambda_k \outp{x_n}\right]-2E\left[\Lambda_k x_n \trans{\mu_k}\right]+E\left[\Lambda_k \outp{\mu_k}\right]\right) \nonumber \\
 &=& \tr E[\nu_k W_k \outp{x_n}]-2\tr E[\nu_k W_k x_n \trans{m_k}]
  + \tr E\left[\Lambda_k(\outp{m_k}+(\beta_k \Lambda_k)^{-1}\right]\nonumber \\
 &=& \nu_k \tr\left(W_k \outp{x_n}\right)-2\nu_k \tr\left(W_k x_n \trans{m_k}\right)+\tr \left(\nu_k W_k \outp{m_k}\right)+D\beta_k^{-1}\nonumber \\
 &=& D\beta_k^{-1} + \nu_k \quads{W_k}{(x_n-m_k)}.
\end{eqnarray}
ウィシャート分布の公式から
$$
\log \tilde{\Lambda}_k := E[\log |\Lambda_k|]=\sum_i \phi\left(\frac{\nu_k+1-i}{2}\right)+D \log 2+ \log |W_k|.
$$
ディリクレ分布の公式から
$$
\log \tilde{\pi}_k := E[\log \pi_k] = \phi(\alpha_k) - \phi(\hat{\alpha}), \quad \hat{\alpha}=\sum_k \alpha_k.
$$

\begin{eqnarray*}
\log \rho_{nk}
 &=& E[\log \pi_k] + \half E\left[\log |\Lambda_k|\right]-\frac{D}{2}\log (2\pi)-\half E\left[\quads{\Lambda_k}{(x_n-\mu_k)}\right]\\
 &=& \log \tilde{\pi}_k + \half\log \tilde{\Lambda}_k
       - \frac{D}{2}\log (2\pi)-\half\left(D\beta_k^{-1}+\nu_k\quads {W_k}{(x_n-m_k)}\right).
\end{eqnarray*}
よって
$$
r_{nk} \propto \rho_{nk} \propto \tilde{\pi}_k \Lambda_k^{1/2} \exp\left(-\frac{D}{2\beta_k} - \frac{\nu_k}{2}\quads{W_k}{(x_n-m_k)}\right).
$$
混合ガウス分布のEMアルゴリズムでの負担率は$\gamma(z_{nk}) \propto \pi_k \calN(x_n|\mu_k, \Lambda_k^{-1})$だったので
$$
r_{nk} \propto \pi_k|\lambda_k|^{1/2} \exp \left(-\half\quads{\Lambda_k}{(x_n-\mu_k)}\right).
$$
これは上の式とよく似ている.

ディリクレ分布の平均の式$E[\mu_k]=\alpha_k/\hat{\alpha}$より
$$
E[\pi_k]=\frac{\alpha_0 + N_k}{\sum_k \alpha_k}=\frac{\alpha_0 + N_k}{K\alpha_0 + \sum_k N_k} = \frac{\alpha_0 + N_k}{K \alpha_0 + N}.
$$
ある混合要素$k$について$r_{nk} \simeq 0$なら$N_k \simeq 0$（PRML p.193はかつとなってるけど片方の条件から出る）.
このとき$\alpha_k \simeq \alpha_0$となる. PRML10章では分布が幅広いという状態を「なだらか」と表記しているようだ.
ちょっとニュアンスが違う気もするけど.

事前分布で$\alpha_0 \rightarrow 0$とすると$E[\pi_k] \rightarrow 0$.
$\alpha_0 \rightarrow \infty$なら$E[\pi_k] \rightarrow 1/K$.

\section{変分下限}
PRML下巻（3刷）ではこの章は変分下限である.
しかしここで計算する$\calL$の値は$\log p(X)$の下界の中で一番大きいものになるとは限らない.
$\KL(q||p)$は一般に0ではない.
その意味で\ref{lower_bound}節で述べたように変分下界が適切と思われる.

それはさておき, $q(Z,\vpi,\mu,\Lambda)=q(Z)q(\vpi,\mu,\Lambda)$と分解できると仮定すると
\begin{eqnarray*}
\calL(q) &=& \int q(Z) \log \frac{p(X,Z)}{q(Z)}\,dZ\\
 &=& \sum \int q(Z,\vpi,\mu,\Lambda) \log \frac{p(X,Z,\vpi,\mu,\Lambda)}{q(Z,\vpi,\mu,\Lambda)}\,d\vpi d\mu d\Lambda\\
 &=& E[\log p(X,Z,\vpi,\mu,\Lambda)]-E[\log q(Z,\vpi,\mu,\Lambda)]\\
 &=& E[\log p(X|Z,\mu,\Lambda)]+E[\log p(Z|\vpi)]+E[\log p(\vpi)]+E[\log p(\mu,\Lambda)]\\
 && - E[\log q(Z)]-E[\log q(\vpi)]-E[\log q(\mu,\Lambda)].
\end{eqnarray*}
以下, ひたすら計算する.
\begin{eqnarray*}
&& E[\log p(X|Z,\mu,\Lambda)]
 = E\left[\sum_{n,k} z_{nk} \log \calN(x_n|\mu_k,\Lambda_k^{-1})\right]\\
 &&= \half E\left[\sum_{n,k} z_{nk}\left(-D \log (2\pi) + \log |\Lambda_k| - \quads{\Lambda_k}{(x_n-\mu_k)}\right)\right]\\
 &&= \half \sum_k E\left[-N_k D \log (2\pi)+N_k \log |\Lambda_k|-\sum_n z_{nk} \quads{\Lambda_k}{(x_n-\mu_k)}\right]\\
 &&= \half \sum_k N_k \left(\log \tilde{\Lambda}_k - D \log (2\pi)\right)
 \\&&\hphantom{={}}
 - \half \underbrace{\sum_{n,k} r_{nk} \left(D\beta_k^{-1}+\nu_k \quads{W_k}{(x_n-m_k)}\right)}_{=:X},
 \\
&&X = \sum_k N_k D\beta_k^{-1} + \sum_k \nu_k \underbrace{\left(\sum_n r_{nk} \quads{W_k}{(x_n-m_k)}\right)}_{=:Y}.
\end{eqnarray*}
式（\ref{r_nk_outp_x_n}）より
$$
\sum_n r_{nk} \outp{x_n}=N_k S_k + N_k \outp{\bar{x}_k}.
$$
よって
\begin{eqnarray*}
Y &=& \tr\left(W_k\left(\sum_n r_{nk} \outp{x_n}-2\sum_n r_{nk} x_n \trans{m_k} + \sum_n r_{nk} \outp{m_k}\right)\right)\\
 &=& \tr(W_k(N_k S_k + N_k \outp{\bar{x}_k} - 2N_k \bar{x}_k \trans{m_k} + N_k \outp{m_k}))\\
 &=& N_k \tr\left(W_k\left(S_k+\outp{(\bar{x}_k-m_k)}\right)\right)\\
 &=& N_k \left(\tr (S_k W_k)+\quads{W_k}{(\bar{x}_k-m_k)}\right).
\end{eqnarray*}
よって
\begin{eqnarray*}
E[\log p(X|Z,\mu,\Lambda)]
 &=& \half \sum_k N_k \Bigl(\log \tilde{\Lambda}_k - D\beta_k^{-1} - \nu_k \tr(S_k W_k)\\
 && -\nu_k \quads{W_k}{(\bar{x}_k-m_k)} - D\log (2\pi)\Bigr).
\end{eqnarray*}
$$
E[\log p(Z|\vpi)=E\left[\sum_{n,k} z_{nk} \log \pi_k\right] = \sum_{n,k} r_{nk} \log \tilde{\pi}_k.
$$
$$
E[\log p(\vpi)]=E\left[\log C(\alpha_0)+\sum_k (\alpha_0-1)\log \pi_k\right]=\log C(\alpha_0)+(\alpha_0-1)\sum_k \log \tilde{\pi}_k.
$$
$$
E[\log q(Z)]=E\left[\sum_{n,k} z_{nk} \log r_{nk}\right]=\sum_{n,k} \log r_{nk}.
$$
$$
E[\log q(\vpi)]=E\left[\log C(\alpha)+\sum_k (\alpha_k-1)\log \pi_k\right]=\log C(\alpha)+\sum_k(\alpha_k-1)\log \tilde{\pi}_k.
$$
\begin{eqnarray*}
&&E[\log q(\mu,\Lambda)]\\
 &=& \sum_k E\left[\log \calN(\mu_k|m_k,(\beta_k \Lambda_k)^{-1})+\log \calW(\lambda_k|W_k,\nu_k)\right]\\
 &=& \sum_k E\left[-\frac{D}{2} \log (2\pi)+\half \log |\beta_k \Lambda_k|
       - \half \quads{(\beta_k \Lambda_k)}{(\mu_k-m_k)}\right]+E[\log W]\\
 &=& \sum_k \half \log \tilde{\Lambda}_k + \frac{D}{2}\log \left(\frac{\beta_k}{2\pi}\right) -
  \half \underbrace{\tr E\left[(\beta_k \Lambda_k)\outp{(\mu_k-m_k)}\right]}_{=:X} + \underbrace{E[\log W]}_{=:Y}.
\end{eqnarray*}
\begin{eqnarray*}
X &=& \tr (\beta_k \Lambda_k)\left(E[\outp{\mu_k}]-2E[\mu_k]\trans{m_k} + \outp{m_k}\right)\\
  &=& \tr (\beta_k \Lambda_k)\left(\outp{m_k} + (\beta_k \Lambda_k)^{-1}-\outp{m_k}\right)
  = \tr I = D.
\end{eqnarray*}
\begin{eqnarray*}
Y &=& E[\log W(\Lambda_k|W_k,\nu_k)]\\
  &=& \log B(W_k,\nu_k)+\frac{\nu_k-D-1}{2} E\left[\log |\Lambda_k|\right] - \half \tr \left(W_k^{-1} E[\Lambda_k]\right)\\
  &=& \log B(W_k,\nu_k)+\frac{\nu_k-D-1}{2} E\left[\log |\Lambda_k|\right] - \half \nu_k D = -H[\Lambda_k].
\end{eqnarray*}
よって
$$
E[\log q(\mu,\Lambda)]=\sum_k \left(\half \log \tilde{\Lambda_k}+\frac{D}{2} \log \left(\frac{\beta_k}{2\pi}\right) - \frac{D}{2}-H[\Lambda_k]\right).
$$

\begin{eqnarray*}
E[\log p(\mu,\Lambda)]
 &=& \sum_k \underbrace{E[\log \calN(\mu_k|m_0,(\beta_0 \Lambda_k)^{-1})]}_{=:A}
       + \underbrace{E[\log \calW(\Lambda_k|W_0,\nu_0)]}_{=:B}.
\end{eqnarray*}
\begin{eqnarray*}
A &=& E\left[-\frac{D}{2}\log (2\pi)+\half \log |\beta_0 \Lambda_k|-\half \quads{(\beta_0 \Lambda_k)}{(\mu_k - m_0)}\right]\\
 &=& \frac{D}{2}\log\left(\frac{\beta_0}{2\pi}\right)+\half \log \tilde{\Lambda}_k-\half \beta_0 E[\quads{\Lambda_k}{(m_0-\mu_k)}]\\
 && （{\text 数ページ前の式（\ref{eval_quad}）でx_n=m_0として使うと}）\\
 &=& \half\left(D\log \left(\frac{\beta_0}{2\pi}\right)+\log \tilde{\Lambda}_k-\beta_0\left(D\beta_k^{-1}+\nu_k\quads{W_k}{(m_0-\mu_k)}\right)\right)\\
 &=& \half\left(D\log \left(\frac{\beta_0}{2\pi}\right)+\log \tilde{\Lambda}_k
      -\frac{D\beta_0}{\beta_k}-\beta_0 \nu_k\quads{W_k}{(m_k-m_0)}\right).
\end{eqnarray*}
\begin{eqnarray*}
B &=& E\left[\log B(W_0,\nu_0)+\frac{\nu_0-D-1}{2}\log |\Lambda_k|-\half \tr (W_0^{-1}\Lambda_k)\right]\\
  &=& \log B(W_0,\nu_0)+\frac{\nu_0-D-1}{2} \log \tilde{\Lambda}_k - \half \tr (W_0^{-1}\underbrace{E[\Lambda_k]}_{=\nu_k W_k}).
\end{eqnarray*}
よって
\begin{eqnarray*}
&&E[\log p(\mu,\Lambda)]
 \\&&
 =\half\sum_k \left(D\log \left(\frac{\beta_0}{2\pi}\right)+\log \tilde{\Lambda}_k-\frac{D\beta_0}{\beta_k}-\beta_0\nu_k\quads{W_k}{(m_k-m_0)}\right)
 \\&&\hphantom{={}}
  + K\log B(W_0,\nu_0)+\frac{\nu_0-D-1}{2}\sum_k \log \tilde{\Lambda}_k - \half \sum_k \nu_k \tr(W_0^{-1}W_k).
\end{eqnarray*}

最後に$\calL$を求めよう.
$$
\sum_k N_k=N,
$$
$$
H[q(\Lambda_k)]=-\log B(W_k,\nu_k)-\frac{\nu_k-D-1}{2}\log \tilde{\Lambda}_k+\frac{\nu_k D}{2}
$$
に注意する.
\begin{eqnarray*}
\calL
 &=& \half \sum_k N_k \log \tilde{\Lambda}_k-\half \sum_k N_k \frac{D}{\beta_k}-\half \sum_k N_k \nu_k \tr(S_k W_k)\\
 &&- \half \sum_k N_k \nu_k\quads{W_k}{(\bar{x}_k-m_k)}\\
 &&- \half\sum_k N_k D \log(2\pi)+\sum_k N_k \log \tilde{\pi}_k\\
 &&+ \log C(\alpha_0)+(\alpha_0-1)\sum_k \log \tilde{\pi}_k+\frac{DK}{2}\log \left(\frac{\beta_0}{2\pi}\right)\\
 &&+ \half \sum_k \log \tilde{\Lambda}_k - \half \sum_k \frac{D\beta_0}{\beta_k}-\half\sum_k \beta_0 \nu_k \quads{W_k}{(m_k-m_0)}\\
 &&+ K \log B(W_0,\nu_0)\\
 &&+ \frac{\nu_0-D-1}{2}\sum_k \log \tilde{\Lambda}_k-\half \sum_k \nu_k\tr(W_0^{-1}W_k) - \sum_{n,k}r_{nk}\log r_{nk}\\
 &&- \sum_k (\alpha_k-1)\log \tilde{\pi}_k -\log C(\alpha) - \half \sum_k \log \tilde{\Lambda}_k - \frac{D}{2}\sum_k \log \frac{\beta_k}{2\pi} +\frac{DK}{2}\\
 &&+ \sum_k \left(-\log B(W_k,\nu_k)-\frac{\nu_k-D-1}{2}\log \tilde{\Lambda}_k+\frac{\nu_k D}{2}\right).
\\
 &=& \log \frac{C(\alpha_0)}{C(\alpha)}\\
 && - \sum_{n,k}r_{nk} \log r_{nk} + \half \sum_k \log \tilde{\Lambda}(N_k+1-\nu_0-D-1-1-\nu_k+D+1)\\
 &&+  \sum_k \log \tilde{\pi}_k(N_k+\alpha_0-1-\alpha_k+1)+K \log B(W_0,\nu_0)- \sum_k \log B(W_k,\nu_k)\\
 && -\frac{DN}{2}\log (2\pi)\\
 &&+ \frac{D}{2}\underbrace{\sum_k\left(\frac{N_k}{\beta_k}+\frac{\beta_0}{\beta_k}\right)}_{=K}
    + \frac{DK}{2}\left(\log \beta_0-\log (2\pi)\right)-\frac{D}{2}\sum_k \log \beta_k+\frac{DK}{2}\log (2\pi)\\
 &&+ \frac{DK}{2}+ \frac{D}{2}\sum_k \nu_k\\
 &&-   \half \sum_k \nu_k \tr\bigl(W_k
    (N_k S_k+N_k\outp{(\bar{x}_k-m_k)}\\
 &&\hphantom{-   \half \sum_k \nu_k \tr\bigl(W_k}
   \underbrace{\qquad+\beta_0\outp{(m_k-m_0)}+W_0^{-1})}_{=:X}\bigr)\\
 &=& \log \frac{C(\alpha_0)}{C(\alpha)}-\sum_{n,k}r_{nk}\log r_{nk}+K \log B(W_0,\nu_0)-\sum_k \log B(W_k,\nu_k)+\frac{DK}{2}\log \beta_0\\
 &&- \frac{D}{2}\sum_k \log \beta_k
 - \frac{DN}{2}\log (2\pi) + \frac{D}{2}\sum_k \nu_k -\half \sum_k \nu_k \tr (W_k X).
\end{eqnarray*}
$$
\bar{x}_k-m_k=\bar{x}_k-\frac{1}{\beta_k}(\beta_0 m_0+N_k \bar{x}_k)=\frac{1}{\beta_k}(\beta_k \bar{x}_k-N_k \bar{x}_k - \beta_0 m0)=\frac{\beta_0}{\beta_k}(\bar{x}_k-m_0).
$$
$$
m_k-m_0=\frac{1}{\beta_k}(\beta_0 m_0+N_k \bar{x}_k)-m_0=\frac{1}{\beta_k}(N_k \bar{x}_k+\beta_0 m_0-\beta_k m_0)=\frac{N_k}{\beta_k}(\bar{x}_k-m_0).
$$
よって
\begin{eqnarray*}
N_k \outp{(\bar{x}_k-m_k)}+\beta_0\outp{(m_k-m_0)}
      &=& \left(\frac{N_k\beta_0^2}{\beta_k^2}+\frac{\beta_0 N_k^2}{\beta_k^2}\right)\\
      &=& \frac{\beta_0 N_k}{\beta_k}\outp{(\bar{x}_k-m_0)}.
\end{eqnarray*}
よって
$$
X=W_k^{-1}, \quad \sum_k \nu_k \tr(W_k W_k^{-1})=D\sum_k \nu_k.
$$
$$
\calL = \log \frac{C(\alpha_0)}{C(\alpha)}-\sum_{n,k}r_{nk} \log r_{nk}+\sum_k \log \frac{B(W_0,\nu_0)}{B(W_k,\nu_k)}
 + \frac{D}{2}\sum_k \log \frac{\beta_0}{\beta_k}-\frac{DN}{2}\log (2\pi).
$$
\section{予測分布}
新しい観測値の予測分布を知りたい.
$$
p(Z|\vpi)=\prod_{n,k} \pi_k^{z_{nk}}, \quad p(X|Z,\mu,\Lambda)=\prod_{n,k} \calN(x_n|\mu_k,\Lambda_k^{-1})^{z_{nk}}
$$
と$\sum_k z_{nk}=1$を使って
\begin{eqnarray*}
p(\hat{x}|X)
 &=& \sum_{\hat{z}} \int p(\hat{x}|\hat{z},\mu,\Lambda)p(\hat{z}|\vpi)p(\vpi,\mu,\Lambda|X)\,d\vpi d\mu d\Lambda\\
 &=& \sum_k \pi_k \int \calN(\hat{x}|\mu_k,\Lambda_k^{-1})
     \underbrace{p(\vpi,\mu,\Lambda|X)}_{\simeq q(\vpi)q(\mu,\Lambda)}\,d\vpi d\Lambda d\mu
\\
 &\simeq& \sum_k \int \pi_k \calN(\hat{x}|\mu_k,\Lambda_k^{-1})q(\vpi)\prod_j q(\mu_j,\Lambda_j)\,d\vpi d\Lambda d\mu\\
 &&\text{（$k\ne j$なら積分して$1$なので）}\\
 &=& \sum_k \int \pi_k \calN(\hat{x}|\mu_k,\Lambda_k^{-1})q(\vpi)q(\mu_k,\Lambda_k)\, d\vpi d\mu_k d\Lambda_k\\
 &=& \sum_k
     \left(\vphantom{\int}\smash{\underbrace{\int \pi_k q(\vpi)\, d\vpi}_{=:X}}\right.
     \vphantom{\underbrace{\int}_{X}}
 \\&&\hphantom{\sum_k}
   \times\left.
     \int \smash{\underbrace{\left(\int \calN(\hat{x}|\mu_k,\Lambda_k^{-1})
      \calN(\mu_k|m_k,(\beta_k \Lambda_k)^{-1})\,d\mu_k \right)}_{=:Y}}
      W(\Lambda_k|W_k,\nu_k) \, d\Lambda_k\right).
    \vphantom{\underbrace{\left(\int\right)}_{=:Y}}
\end{eqnarray*}
$X$, $Y$をそれぞれ計算する：
$$
X=\int \pi_k \Dir(\vpi|\alpha)\, d\vpi=\frac{\alpha_k}{\hat{\alpha}}.
$$
\begin{eqnarray*}
A
 &:=& \int \calN(x|\mu,\Lambda^{-1})\calN(\mu|m,(\beta \Lambda)^{-1})\,d\mu\\
 &\phantom{:}=& \int \frac{1}{(2\pi)^D}|\Lambda|^{1/2}|\beta \Lambda|^{1/2}\exp\left(-\half \Lambda
 \smash{\underbrace{\left(\outp{(x-\mu)}+\beta \outp{(\mu-m)}\right)}_{=:B}}\right)\,d\mu
 \vphantom{\underbrace{\left(\outp{(x-\mu)}\right)}_{=:B}}
 ,
\\
B
 &=& (\beta+1)\outp{\mu}-2\mu\trans{(x+\beta m)}+\outp{x}+\beta \outp{m}\\
 &=& (\beta+1)\outp{\left(\mu-\frac{1}{\beta+1}(x+\beta m)\right)}\\
 &&+ \underbrace{\outp{x}+\beta \outp{m} - \frac{1}{\beta+1}\outp{(x+\beta m)}}_{=:C}
 ,
\\
C
&=&\frac{\beta}{\beta+1}\outp{x}+\frac{\beta^2+\beta-\beta^2}{\beta+1}\outp{m}-\frac{2 \beta}{\beta+1}x\trans{m}
 = \frac{\beta}{\beta+1}\outp{(x-m)}.
\end{eqnarray*}
よって
\begin{eqnarray*}
A
 &=& \int \calN\left(\mu\Bigl|\frac{x+\beta m}{\beta + 1}, \left((\beta+1)\Lambda\right)^{-1}\right)\frac{1}{(2\pi)^{D/2}}
      \frac{|\beta \Lambda^2|^{1/2}}{|(\beta+1)\Lambda|^{1/2}}\\
 &&\phantom{\int}
   \times \exp\left(-\half \quads{\left(\frac{\beta}{\beta+1}\Lambda\right)}{(x-m)}\right)\,d\mu
  = \calN\left(x\Bigl|m,\left(\frac{\beta}{\beta+1}\Lambda\right)^{-1}\right).
\end{eqnarray*}
つまり
$$
Y = \calN\left(\hat{x}\Bigl|m_k,\left(\frac{\beta_k}{\beta_k+1}\Lambda_k\right)^{-1}\right).
$$
\begin{eqnarray*}
&&D
 := \calN\left(x\Bigl|m,\left(\frac{\beta}{\beta+1}\Lambda\right)^{-1}\right)W(\Lambda|W,\nu)\\
&&\phantom{D{:}}=
  \frac{1}{(2\pi)^{D/2}}\left|\frac{\beta}{\beta+1}\Lambda\right|^{1/2}
  \exp\left(-\half \tr\left(\Lambda \frac{\beta}{\beta+1}\outp{(x-m)}\right)\right)\\
&&\phantom{D:={}}
    \times B(W,\nu)|\Lambda|^{\frac{\nu-D-1}{2}}\exp\left(-\half \tr(W^{-1}\Lambda)\right),
\\
&&W'^{-1}
 := W^{-1}+\frac{\beta}{\beta+1}\outp{(x-m)}
\end{eqnarray*}
とおく.
$\left|I+a\trans{b}\right|=1+\trans{a}b$より$W=\trans{W}$のとき
$$
\left|W^{-1}+\outp{x}\right|=\left|W^{-1}\right|\left|I+W\outp{x}\right|=|W|^{-1}\left(1+\quads{W}{x}\right).
$$
よって
\begin{eqnarray*}&&
|W'^{-1}|
=|W|^{-1}
  \left(1+\smash{\underbrace{\frac{\beta}{\beta+1}\quads{W}{(x-m)}}_{=:\lambda}}
  \vphantom{\frac\beta\beta}
  \right)
  \vphantom{\underbrace{\frac\beta\beta}_{\lambda}}
=|W|^{-1}(1+\lambda),
\\&&
|W'|=|W|\left(\frac{1}{1+\lambda}\right).
\end{eqnarray*}
よって
\begin{eqnarray*}
&&\int D\,d\Lambda\\
 &&= \left(\frac{\beta}{2\pi(\beta+1)}\right)^{D/2}\frac{B(W,\nu)}{B(W',\nu+1)}
 \\&&\phantom{={}}\quad
     \times
     \underbrace{\int B(W',\nu+1)|\Lambda|^{\frac{(\nu+1)-D-1}{2}}\exp\left(-\half \tr (W'^{-1}\Lambda)\right)\,d\Lambda}_{=1}\\
 &&= \left(\frac{\beta}{2\pi(\beta+1)}\right)^{D/2}
      \frac{|W'|^{(\nu+1)/2}2^{(\nu+1)D/2}\pi^{D(D-1)/4}\prod_i \Gamma\left(\frac{\nu+2-i}{2}\right)}
           {|W|^{\nu/2} 2^{\nu D/2} \pi^{D(D-1)/4} \prod_i \Gamma\left(\frac{\nu+1-i}{2}\right)}\\
 &&= \left(\frac{\beta}{\pi(\beta+1)}\right)^{D/2}\frac{\Gamma\left((\nu+1)/2\right)}{\Gamma\left((\nu+1-D)/2\right)}\left(\frac{1}{1+\lambda}\right)^{\nu/2}
      |W|^{1/2}\left(\frac{1}{1+\lambda}\right)^{1/2}\\
 &&= \frac{\Gamma\left((\nu+1)/2\right)}{\Gamma\left((\nu+1-D)/2\right)} \left(\frac{\beta}{\pi(1+\beta)}\right)^{D/2}|W|^{1/2}(1+\lambda)^{-(\nu+1)/2}\\
 &&= \frac{\Gamma(\frac{\nu+1}{2})}{\Gamma\left(\frac{\nu+1-D}{2}\right)} \frac{\left(\frac{\beta(\nu+1-D)}{1+\beta}\right)^{\frac{D}{2}}}
       {(\nu+1-D)^{\frac{D}{2}}\pi^{\frac{D}{2}}} |W|^{\frac{1}{2}}
 \\&&\phantom{={}}\quad
     \times
       \left(1+\frac{\quads{\left(\frac{\beta(\nu+1-D)}{1+\beta}W\right)}{(x-m)}}{\nu+1-D}\right)^{\frac{-(\nu+1)}{2}}\\
 &&= \St(x|m,L,\nu+1-D), \quad L:=\frac{\beta(\nu+1-D)}{1+\beta}W.
\end{eqnarray*}
よって
$$
p(\hat{x}|X) \simeq \frac{1}{\hat{\alpha}}\sum_k \alpha_k \St(\hat{x}|m_k,L_k,\nu_k+1-D).
$$
だいたいこのあたりまで. あとはここよりは易しいので大丈夫だろう.

PRML下巻p.215の下から5行目：
「$\lambda'(\xi)$は$\xi \ge 0$のとき単調関数」とあるが間違い.
$\lambda(\xi)$は$\xi \ge 0$のとき単調減少だが$\lambda'(\xi)$はそうではない.
また$\lambda(\xi)$が単調減少だからといってそれだけで$\lambda'(\xi) \ne 0$が言えるわけでもない.

